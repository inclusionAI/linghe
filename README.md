

<h1 align="center">FLood OPS(FLOPS) </h1>

  
<p align="center">
   A high-performance kernels to accelerate LLM inference and training.
</p>


## *News or Update* ðŸ”¥

- [2025/07] We implement multiple kernels for fp8 training with smooth quant.


## Introduction

Our repo, FLOPS (short for Flood OPS), is designed for LLM inference and training.

